---
title: "00_texts_separation"
format: html
editor: visual
---

```{r}
library(tidyverse)
```

# Collections

```{r}
lf <- list.files("../../data/cols_test/",
                 pattern = ".txt", 
                 full.names = TRUE)

head(lf)

dat <- tibble(path = lf,
              text = sapply(lf, read_file))

str(dat)
```

## Extract metadata

```{r}
dat_meta <- dat %>% 
  # extract metadata tags
  mutate(col_id = str_extract(text, "<id: .*?>"), 
         year = str_extract(text, "<year: .*?>"),
         descr = str_extract(text, "<descr: .*?>")) %>% 
  # clean metadata tags
  mutate(col_id = str_remove_all(col_id, "<|id:|>|\\s"),
         col_id = paste0("C_", col_id),
         year = str_remove_all(year, "<year:|>|\\s"),
         descr = str_remove_all(descr, "<descr:\\s?|>")) %>% 
  
  # remove metadata from the texts
  mutate(text = str_remove_all(text, 
                               "<id:.*?>|<year:.*?>|<descr:.*?>")) 

str(dat_meta)
rm(dat)
```

## Text separation

```{r}
dat_cln <- dat_meta %>% 
  # remove unnecessary spaces left after metadata removal
  mutate(text = str_remove(text, "^\n\n\n\n\n?")) %>% 
  
  # add separator between each text id tag
  mutate(text = str_replace_all(text, "<title:", "<new_text><title:")) %>% 
  
  # separate each text to a row
  separate_rows(text, sep = "<new_text>") %>% 
  # remove empty rows
  filter(text != "") %>% 
  filter(str_detect(text, "<title:")) %>% 
  
  # extract text title and subtitle
  mutate(# extraction
         title = str_extract(text, "<title:.*?>"),
         subtitle = ifelse(str_detect(title, "\\|\\|sub:"),
                           str_extract(title, "\\|\\|sub:\\s?.*?>"),
                           ""),
         # cleaning
         title = str_remove_all(title, "\\|\\|sub:.*?>"),
         title = str_remove_all(title, "<title:\\s?|>"),
         subtitle = str_remove_all(subtitle, "\\|\\|sub:\\s?|>"),
         
         # clean text from tag
         text_cln = str_remove_all(text, "<title:.*?>")
         ) %>% 
  
  # extract pages of the text
  mutate(pages = str_extract(text, "<pages:.*?>"),
         pages = str_remove_all(pages, "<pages:|\\s|>"),
         text_cln = str_remove_all(text_cln, "<pages:.*?>")
         ) %>% 
  
  # extract notes & authors for almanack-type editions
  mutate( #extraction
    notes = str_extract(text, "<notes:.*?>"),
    author = ifelse(str_detect(notes, "\\|\\|author:"),
                         str_extract(notes, "\\|\\|author:.*?>"),
                         ""),
    
    # cleaning
    author = str_remove_all(author, "\\|\\|author:\\s?|>"),
    author = str_replace_all(author, "NA", "Unknown"),
    notes = str_remove_all(notes, "<notes:\\s?|\\|\\|author:.*?>|>"),
    # text cln from notes
    text_cln = str_remove_all(text_cln, "<notes:.*?>")
    ) %>% 
  
  # extract genre_title
  mutate(genre_title = str_extract(text, "<genre title:.*?>"),
         genre_title = str_remove_all(genre_title, "<genre title:\\s|>"),
         text_cln = str_remove_all(text_cln, "<genre title:.*?>")) %>% 
  
  # final text cleaning from \n\n
  mutate(text_cln = str_remove_all(text_cln, "^\\n\\n\\n?|\\n?\\n?\\n?$")) %>% 
  
  # add text_id
  group_by(col_id) %>% 
  mutate(text_id = paste0(col_id, "__", row_number())) %>% 
  ungroup() %>% 
  
  # create path for separate files:
  mutate(path_text = paste0("../../data/cols_test/texts//", text_id, ".txt" )) %>% 
  
  # create first line column
  mutate(first_line = ifelse(!str_detect(text_cln, "^<"),
           str_extract(text_cln, "^.*?\\n"),
           str_extract(text_cln, "\\n.*?\\n")
           ),
         first_line = str_remove(first_line, "^\\n|\\n$")) %>% 
  
  select(path, path_text, col_id, year, author, 
         text_id, title, subtitle, genre_title, first_line, pages, notes, 
         text_cln, text, descr)
  
str(dat_cln)
```

## Write texts and metadata

```{r}
#getwd()

# write texts 
for (i in 1:nrow(dat_cln)) {
  write_file(x = dat_cln$text_cln[i], file = dat_cln$path_text[i])
}

# write metadata
# str(dat_cln)
write.csv(dat_cln %>% select(-text, -text_cln), 
          file = "../../meta/collections_texts_meta.csv") 
```

```{r}
dat_cln %>% 
  filter(text_id == "C_69__21") %>% 
  select(text_cln) %>% pull
```

# Periodicals

## Load data

Read all .txt files in a folder

```{r}
fl <- list.files("../../misc/raw_ocr/per_raw", # select folder
                 pattern = ".txt",
                 full.names = T)

print("filelist:")
fl # check filelist

dat <- tibble(file = fl,
            text = sapply(fl, read_file)) # read files with sapply

head(dat)
```

## Extract id-s

```{r}
dat_cln <- dat %>% 
  # add a <text_end> tag before each id for easier separation
  mutate(text = str_replace_all(text, "<id:", "<text_end><id:")) %>% 
  # separate rows by the tag
  separate_rows(text, sep = "<text_end>") %>% 
  # filter possible empty lines
  filter(text != "") %>% 
  # extract ids
  mutate(id = str_extract(text, "<id:.*?>")) %>% 
  # check if other tags are present
  mutate(other_tags = str_extract(text, "<\\w+:.*?>")) %>% 
    
  # main cleaning: 
  # edit id-s from numbers to text id-s
  mutate(id = str_remove_all(id, "<|>|id:\\s?"),
         path = paste0("P_", id, ".txt"),
         # remove all tags from texts (everything in <>)
         text = str_remove_all(text, "<\\w+:.*?>"),
         # remove newline(s) from the text beginning
         text = str_remove(text, "^\n\n?|\n\n\n?$")
         )

head(dat_cln)
nrow(dat_cln) # number of poems separated
```

## Check before writing

Id-s & paths

```{r}
print(c(
  "Number of unique id-s are equal to number of rows:", 
  nrow(dat_cln) == length(unique(dat_cln$id))
  ))

# show duplicates
# dat_cln[duplicated(dat_cln$id),]

# check paths
head(unique(dat_cln$path))
```

## Write texts as separate files

```{r}
getwd()
setwd("../../misc/raw_ocr/per_raw/mn/")

for (i in 1:nrow(dat_cln)) {
  write_file(x = dat_cln$text[i], file = dat_cln$path[i])
}

#write_file(x = dat_cln$text[1], file = dat_cln$path[1])
```

## test: attach per to meta

```{r}
lf <- list.files(path = "../../misc/raw_ocr/per_add/",
                 pattern = ".txt",
                 full.names = F)
head(lf)
length(lf)

test_vec <- str_remove_all(lf, ".txt")
```

```{r}
meta <- read.delim("../../meta/per_meta_140723.tsv", 
                   sep = "\t") %>% 
  filter(First_line != "") # 1870 texts

# 1403 texts
per_texts <- read.csv("../../data/periodicals_lem.csv") %>% rename(text_ID = id)

meta %>% 
  anti_join(per_texts, by = "text_ID") %>% # 468 texts to be added
  filter(!text_ID %in% test_vec) %>%  # 182 to go
  count(PER_ID, Year, sort = T)
  #filter(PER_ID == "БдЧ")
```
