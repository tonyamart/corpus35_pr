---
title: "03_corpus_overview"
format: md
editor: visual
---

# Corpus overview

## load pckg

```{r}
library(tidyverse)
library(tidytext)

library(MetBrewer)
theme_set(theme_minimal())
```

## load data

```{r}
corpus_1835 <- readRDS("../../data/corpus1835/corpus_1835.Rds")
glimpse(corpus_1835)
```

## total size

```{r}
print(paste0("Number of poems: ", nrow(corpus_1835)))

print(paste0("Number of poems in periodicals: ", table(corpus_1835$corpus)[2]))
print(paste0( "Number of poems in collections: ", table(corpus_1835$corpus)[1]))

print("Number of lines:")
corpus_1835 %>% 
  select(corpus, text_raw) %>% 
  separate_rows(text_raw, sep = "\n") %>% 
  filter(text_raw != "") %>% nrow()

corpus_1835 %>% 
  select(corpus, text_raw) %>% 
  separate_rows(text_raw, sep = "\n") %>% 
  filter(text_raw != "") %>% 
  count(corpus)


print("Number of tokens:")
corpus_1835 %>% 
  select(corpus, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>% 
  nrow()

corpus_1835 %>% 
  select(corpus, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>% 
  count(corpus) 

  
print("Number of lemmas:")
corpus_1835 %>% 
  select(corpus, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>% 
  count(word) %>% nrow

corpus_1835 %>% 
  select(corpus, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>% 
  count(corpus, word) %>%
  select(-n) %>%
  ungroup() %>%
  count(corpus)
```

## size - poems

```{r}
corpus_1835 %>% 
  count(year, corpus) %>% 
  ggplot(aes(x = year, y = n, fill = corpus)) + geom_col(position = "dodge")

corpus_1835 %>% 
  count(year, corpus) %>% 
  ggplot(aes(x = year, y = n, fill = corpus)) + geom_col(position = "stack")

```

## size - tokens

```{r}
tokens <- corpus_1835 %>% 
  select(corpus, year, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>% 
  count(corpus, year)
  
tokens %>%  
  ggplot(aes(x = year, y = n, fill = corpus)) + geom_col(position = "dodge")

tokens %>% 
  ggplot(aes(x = year, y = n, fill = corpus)) + geom_col(position = "stack")

sum(tokens$n)
```

## size - authors' corpus

Poems

```{r}
corpus_1835 %>%
  filter(author_text != "") %>% 
  count(author_text, corpus, sort = T) %>% head(20)

corpus_1835 %>%
  filter(author_text != "") %>% 
  count(author_text, corpus, sort = T) %>% 
  ggplot(aes(x = reorder_within(author_text, -n, -n), y = n, fill = corpus)) + geom_col() + 
  theme(axis.text.x = element_blank())
```

Number of tokens by authors

```{r}
corpus_1835 %>%
  #filter(author_text != "") %>% 
  select(author_text, corpus, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>%
  count(author_text, sort = T) %>% head(30)

corpus_1835 %>%
  # filter(author != "") %>% 
  select(author_text, corpus, text_lemm) %>% 
  unnest_tokens(input = text_lemm, output = word, token = "words") %>%
  count(author_text, corpus, sort = T) %>% 
  ggplot(aes(x = reorder_within(author_text, -n, -n), y = n, fill = corpus)) + 
  geom_col() + 
  geom_hline(yintercept = 2000, color = "blue") + 
  theme(axis.text.x = element_blank())
```

# Subtitles & genres

Simple word counter for genres and keywords in titles

```{r}
corpus_1835 %>% 
  mutate(title_words = paste(text_title, text_subtitle)) %>% 
  filter(text_title != "NA" & text_subtitle != "na") %>% 
  select(text_id, text_title, title_words) %>% 
  unnest_tokens(input = title_words, output = word, token = "words") %>%
  #filter(word == "е") #%>% 
  count(word, sort = T) 

# things like separate letters ("e") came from titles with abbreviated names ("To E.E.")


```

```{r}
titles <- corpus_1835 %>% 
  mutate(title_words = paste(text_title, text_subtitle)) %>% 
  filter(text_title != "NA" & text_subtitle != "na") %>% 
  select(text_id, text_title, title_words) %>% 
  unnest_tokens(input = title_words, output = word, token = "words") #%>%
  #filter(word == "е") #%>% 
  #count(word, sort = T) 

# write.csv(titles, "poems_titles.csv") # write to lemmatise


```

Load titles

```{r}
titles <- read.csv("poems_titles.csv") %>% select(-X)

head(titles)
```

Count lemmas in titles

```{r}
titles_counter <- titles %>% 
  count(lemma, sort = T)

titles_counter
```

Count N of periodicals and books texts

```{r}
# total number of texts in periodicals and in collections
n_corpus <- corpus_1835 %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus) %>% 
  rename(total = n)

n_corpus
```

Look into particular lemmas

```{r}
# genres

# шарада
# омоним
# русский

genres <- unlist(str_split(c("песня
романс
сонет
элегия
басня
песнь
альбом
дума
баллада
отрывок
подражание
послание
молитва
фантазия
псалом
эпиграмма
мелодия
антологический
аполог
сказка
экспромт
эпилог"), pattern = "\n"))

titles_counter %>% 
  filter(lemma %in% genres)

# roughly % of texts with genre titles
titles %>% 
  filter(lemma %in% genres) %>% 
  distinct(text_id) %>% 
  count() %>% 
  mutate(perc = n/nrow(corpus_1835)*100)


# same % but divided for periodicals and collections
titles %>% 
  filter(lemma %in% genres) %>% 
  distinct(text_id) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = n/total*100)

titles %>% 
  filter(lemma %in% genres) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus, lemma, sort = T) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = round(n/total*100, 2)) %>% select(-n, -total) %>% 
  pivot_wider(names_from = corpus, values_from = perc)

titles %>% 
  filter(lemma %in% genres) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus, lemma, sort = T) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = round(n/total*100, 2),
         corpus = ifelse(corpus == "P", "Периодика", "Отд. изд.")) %>% 
  select(-n, -total) %>% 
  ggplot(aes(x = reorder_within(lemma, by = perc, within = lemma), 
             y = perc, 
             fill = corpus)) + 
  scale_x_reordered() + 
  coord_flip() + 
  geom_col(position = "dodge",
           width = 0.8) + 
  labs(x = "", 
       y = "% от всех текстов",
       fill = "Корпус") +
  scale_fill_manual(values = c(met.brewer("Veronese")[3],
                               met.brewer("Veronese")[6])) + 
  theme(axis.text = element_text(size = 12))
```

Topic titles (words with freq \> 10 are selected)

```{r}
topics <- unlist(str_split("поэт
ночь
она
смерть
друг
жизнь
любовь
море
могила
красавица
сон
роза
цветок
соловей
звезда
дева
певец
видение
мечта
разлука
слеза
вечер
орел
сердце
сестра
ангел
воин
желание
змея
мысль
признание
утешение
чувство
вдохновение
гений
конь
время
грусть
девица
крестьянин
лисица
мать
москва
родина
тоска
возрождение
гроза
пловец
степь
человек
весна
волк
девушка
душа
ночной
свет
война
гора
древний
идеал
книга
младенец
невеста
развалины
счастие
утро
художник
юноша", pattern = "\n"))

# roughly % of texts with topic titles
titles %>% 
  filter(lemma %in% topics) %>% 
  distinct(text_id) %>% 
  count() %>% 
  mutate(perc = n/nrow(corpus_1835)*100)


# same % but divided for periodicals and collections
titles %>% 
  filter(lemma %in% topics) %>% 
  distinct(text_id) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = n/total*100)

titles %>% 
  filter(lemma %in% topics) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus, lemma, sort = T) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = round(n/total*100, 2),
         corpus = ifelse(corpus == "P", "Периодика", "Отд. изд.")) %>% 
  select(-n, -total) %>% 
  ggplot(aes(x = reorder_within(lemma, by = perc, within = lemma), 
             y = perc, 
             fill = corpus)) + 
  scale_x_reordered() + 
  coord_flip() + 
  geom_col(position = "dodge",
           width = 0.8) + 
  labs(x = "", 
       y = "% от всех текстов",
       fill = "Корпус") +
  scale_fill_manual(values = c(met.brewer("Veronese")[3],
                               met.brewer("Veronese")[6])) + 
  theme(axis.text = element_text(size = 12))
```

Names

```{r}
n <- unlist(str_split(
  "гете
гюго
байрон
пушкин
наполеон
ламартин
шиллер",
  pattern = "\n"
))

# roughly % of texts with topic titles
titles %>% 
  filter(lemma %in% n) %>% 
  distinct(text_id) %>% 
  count() %>% 
  mutate(perc = n/nrow(corpus_1835)*100)


# same % but divided for periodicals and collections
titles %>% 
  filter(lemma %in% n) %>% 
  distinct(text_id) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = n/total*100)

titles %>% 
  filter(lemma %in% n) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus, lemma, sort = T) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  select(-total) %>% 
  pivot_wider(names_from = corpus, values_from = n)

```

Specific words

```{r}
n <- unlist(str_split(
  "1837
русский
славянин
славянский
солдатский
москва",
  pattern = "\n"
))

# roughly % of texts with topic titles
titles %>% 
  filter(lemma %in% n) %>% 
  distinct(text_id) %>% 
  count() %>% 
  mutate(perc = n/nrow(corpus_1835)*100)


# same % but divided for periodicals and collections
titles %>% 
  filter(lemma %in% n) %>% 
  distinct(text_id) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  mutate(perc = n/total*100)

titles %>% 
  filter(lemma %in% n) %>% 
  mutate(corpus = str_extract(text_id, "^\\w")) %>% 
  count(corpus, lemma, sort = T) %>% 
  left_join(n_corpus, by = "corpus") %>% 
  select(-total) %>% 
  pivot_wider(names_from = corpus, values_from = n)

```

# words

## iambs
